\section{Discussion}
\label{sec:discussion}
Before concluding, we discuss some design decisions:  the focus on Credit Distribution (as opposed to Credit Generation), and the choice of Distribution Strategies.

\subsection{Credit Generation}
\label{subsec: generation}
\rtwo{In this paper we focused on Credit Distribution, the problem of distributing credit generated by a citation to the parts of the database referenced by the query.
A different problem is Credit Generation, the task of generating credit which is then distributed. 
Credit Generation presents a series of issues which are shared by traditional citation practices. For instance, defining the  quantity of credit to be generated for a given citation is still an open problem. Different types of citations may generate different quantities of credit. 
\scream{SBD:  Not sure what the next sentence means:  "related to the results"?  I get "previous work".}
Data cited as related to the results or as useful for previous work may generate less credit than other data extensively used to produce the results presented in a paper. The computation of credit could be done manually (although we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still not agreed upon for data or for traditional citation. For this reason, we used a uniform credit assignment.
}

\rtwo{There is also the problem of \emph{transitive credit distribution}, i.e., how to transitively propagate credit from one cited unit to another unit that was used to produce the one being cited. For this, 
%it is possible to envision 
a graph of cited units that propagate credit between the units depending on  influence could be used. How to propagate credit is an open and non-trivial problem that needs to consider the importance and impact of a citation in a work, be it a paper or data, and how to eventually compute the quantity of credit to be propagated.}


\todo[size=\scriptsize]{GMS: I commented out a list of items I did not agree much with. Please take a look and resume what you think is good for you (if any). -- DD: Some of the points were raised because of Reviewer 2. Since we discuss about them in the first paragraph, we can keep the list out of the paper. I added another paragraph to add more meat for reviewer 2, it can be removed too.} 

%% list commented OUT (11 Dec 2021)
\eat{
\begin{enumerate}
	\item \emph{How much credit should be generated?} Different types of citations may generate different quantities of credit. Data cited as related to the results or as useful for previous work of a study may generate less credit than other data extensively used to produce the results presented in a paper. The computation of the credit could be done manually (even though we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still far from reaching both for data and traditional citations. For this reason, for the time being, a uniform credit assignment looked more appealing and realistic to us.\todo[size=\scriptsize]{GMS: commented out the part about NLP; it does not make sense to me. and removed self-citations, that's debatable, not data specific and we do not want to go there.}
	%Different techniques may be employed to compute credit reflecting the impact of the data being cited. The manual annotation by the authors of the data that are more relevant to the economy of the paper is a possibility . Some forms of automatic annotation could be or computations performed through NLP techniques to infer the importance of a citation based on the context of the text where it is cited.
	%\item \emph{Credit produced by self-citations} Data credit, being built on top of traditional citations, inherits some of its problems. Authors, using self-citations, may generate and distribute credit to themselves, making their work appear much more impactful that it actually is. Different strategies may be exploited in this scenario, ranging from ignoring completely the credit generated from self-citations to applying a discount factor to control it.
	\item \emph{Generic citations} As we mentioned, citations may go to the whole database, or to views of the database computed using a big portion of its data. In this case, credit may be assigned indiscriminately to large portions of data, losing the ability to accurately identify parts of the database that have high impact. In this case it is also possible to ignore queries that are too ``general'' and considering only queries that are discriminative enough.\todo[size=\scriptsize, color=green]{this is not about credit generation but distribution. I do not think this is needed (+ I do not know if I agree with this. remove?)}
	\item \emph{Different types of credit} In the real world, there are different types of research communities interested in information in a database. Doctors' interests and queries may differ from the interests and queries of ophthalmologists or pharmacists. For this reason, only distributing one generic credit generated from all possible queries coming from this heterogeneous set of users may simply highlight data that are important in general, without taking into consideration the specific their specific and different needs. One possibility is to keep separated the credit generated by different types of users, e.g., have one type of credit generated from queries coming from doctors, another type of credit generated from queries submitted by ophthalmologists, etc. In this way, it will be possible to accurately tailor the process of credit distribution around the information need of different categories of users. 
\end{enumerate}
}

\scream{SBD: Revised below, make sure you are ok with it.}

\eat{
\rone{Finally, in our experiments we assumed that the credit carried by an output tuple is one. Thus, each tuple in the output has equal importance. As described above, this assumption may be revised and different credit to different output tuples could be assigned.}

%% again? redundant with above
%This in general may not be true, since different tuples in the output may have different weight, depending on the context of the citation. For example, data that is fundamental for the results of a paper may have more credit than data being cited as a reference. 
%\emph{Credit generation}, i.e. the process by which the credit of the output tuples is decided, is a research problem with its own dignity and complexities, and we did not face it in this paper.}

\rone{Nonetheless, from the distribution models viewpoint no change is required since the DCD is defined for a generic value $k$. Of course, note that if the quantity of credit carried by an output tuple changes, as a consequence the final distribution will change too, since certain tuples will be more ``impactful'' (i.e., distribute more credit) than others.}
}

\rone{Finally, in our experiments we assumed that the credit carried by an output tuple is one. Thus, each tuple in the output has equal importance. As described above, this assumption may be revised and different credit to different output tuples could be assigned.  Note that from the distribution model viewpoint no change is required since the DCD is defined for a generic value $k$. }



\subsection{Choice of Distribution Strategies}
\label{subsec: DSs}
\rone{In this paper we presented four different DSs, so the natural question is which one to use.  This depends on the task at hand.   When we want to highlight the tuples being used in the database by a workload, the lineage-based DS may be sufficient. When we also want to know the relative impact of tuples in the context of the query, the other DSs should be used since they give a better understanding of the importance of data.}

% \todo[size=\scriptsize]{GMS: Not superconvinced of the following paragraph. is it good to talk about SPARQL when we say that relational DBs are still widely used? Alternative example with SQL? Or do we just remove it?}
\rone{In the real-world based experiments, the four DSs behaved the same, which was due to the specific nature of the data and the queries being used. However, the why-provenance of a query will differ from the lineage of the same query whenever the output tuples can be computed in more than one way by the query, i.e., if there is more than one witness. This is usually true when join and projection operators are used in the query.
% There are several situations where the user-submitted queries present different distribution of credit.
% For instance, the work by \citet{BonifatiMT17} showed that in the context of SPARQL query logs submitted to various databases such as DBpedia and Wikidata, more than $90\%$ of these queries are of type select, and of those more than $30\%$ perform join operations through the \texttt{and} operator. These queries contain triple patterns with cardinalities that range from one to eleven triples, thus showing some complexity that can be caught by why- and how-provenance based DSs.
} 

\scream{SBD: this paragraph went all over the place and was confusing.  I eliminated a lot of details that you might think are important (original is in an eat environment.}

\rone{To address the question of what types of queries are likely to extract cited data, we turn to the results of published studies on the characteristics of query workloads and the complexity of their queries~\cite{Vogelsgesang2018get,Remil2021makes,Jain2016sqlshare}.  
These studies show that operations such as inner-/outer-joins and projections occur in a significant number of queries.  Therefore why- and how-provenances may become quite complex in certain cases and provide a distribution of credit that is significantly different from the one obtained with lineage. }


\eat{
\rone{To address the question of what types of queries are likely to extract cited data, we turn to the results of published studies.  In \cite{Vogelsgesang2018get}, which studies the characteristics of query workloads and the complexity of their queries, they showed that operations such as inner joins can be found in at least $4.5\%$ of queries in the considered workload, %with a maximum number of times the operator is used in the same query equal 
and used up to to $164$ times in the same query. Outer joins were found in $1\%$ of the queries, and used up to $247$ times in the same query. }
\rone{\cite{Remil2021makes} showed that in the query workload of one company 520 queries out of 140K used joins, while 3470 used projections. }
\rone{\cite{Jain2016sqlshare} shows instead that 11\% of the queries in their  workflow used outer join. Moreover, 2.5\% of the considered views access other datasets, and 10\% of the queries logged in the system access datasets that the query author does not own. It also showed that many queries are short in their considered workload in terms of ASCII characters being used (circa 20\% are under 100 characters), on the other hand the longest query range up to 11375 characters. The simple length is not necessarily equivalent to complexity, thus the authors also showed that, while many of the considered queries have less than 4 distinct operators, a percentage around 30 and 60\% of queries, depending on the workload, present a number of distinct operators between 4 and 8. Finally, the considered queries also showed a higher entropy, i.e., they were particularly different among them.}

\rone{
These works provide us evidence of the fact that, potentially, why- and how-provenances may become quite complex in certain cases and provide a distribution of credit different from the one obtained with lineage. 
}
}

\scream{Is there more to say here? What are the general queries for which responsibility is hard to compute, and can the various provenances handle them at all?  I know that provenance semi-rings has been extended to SPJU and aggregate queries, so imagine this means the others can be extended since it is a general framework.}   
\rtwo{From a complexity standpoint, all four DS are similar since we focused on SPJ queries. However, responsibility is hard to compute for general queries.  In terms of implementation, lineage is the simplest to compute since it only cares about a tuple being used, while the other provenances also need additional information to be taken into consideration.}

\eat{
Another promising DS that could be developed is one based on Shapley values. This function has been widely used in knowledge representation and machine learning, and has strong theoretical justifications.  However, its use in databases as a metric for quantifying the influence of a tuple on the output of a query (thereby presenting an alternative to responsibility) has only recently been proposed~\cite{LivshitsBKS20}.    Furthermore, the initial theoretical analysis in~\cite{LivshitsBKS20} showed mainly lower bounds on the complexity of the problem, and did not suggest a feasible implementation.  However, very recently, an efficient implementation for boolean queries (queries that output true or false) has been provided~\cite{DFKM22}, both in terms of an exact computation (which in practice works well for most queries) and an inexact one (which is extremely fast and provides the same ranking of tuples as the exact computation, but not necessarily the same values).  In future work, we will explore a Shapley-based DS and test its performance in Credit Distribution.}


\eat{
In particular, Shapley has (at least) four properties that are widely believed to be important:
\begin{enumerate}
\item 
Efficiency:  The sum of the Shapley values of all agents equals the value of the grand coalition, so that all the gain is distributed among the agents.  
\item
Symmetry:  If i and j are two actors who are equivalent in the sense that v(S U {i})= v(S U {j}) for every subset S of N that contained neither i nor j, then their Shapley values are the same.
\item
Linearity:  If two coalition games described by gain functions v and w are combined, then the distributed gains should correspond to the gains derived from v and the gains derived from w.
Shap_i(v+w)= Shap_i(v) + Shap_i(w) for every I in N.  
Also, for any real number a,  Shap_i(a*v)=a*Shap(v)
\item
Null player:  The Shapley value of a null player i in a game v is zero.  A player i is null if v(S U {I}) = v(S) for all coalitions S that do not contain i. 
\end{enumerate}

The provenance-based approaches certainly satisfy 1and 4, and I believe that at least why- and how-provenance satisfy 2.  However, they don’t satisfy linearity (Nave gave me a counterexample for this).
}