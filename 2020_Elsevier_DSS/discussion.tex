\section{Discussion}
\label{sec:discussion}

\rtwo{\paragraph{Credit Generation} In this paper we focused on Credit Distribution, the problem of distributing credit generated by a citation to the parts of the database being used by the query subsumed by that citation.
A different problem is credit generation, the task of generating credit \emph{before} it distribution. 
Credit generation presents, in itself, a series of new problems. Among them, we count here:
\begin{enumerate}
	\item \emph{The correct generation of credit} Different types of citations may generate different quantities of credit. Data being cited in the related work may generate less credit than a result set of data that are extensively used throughout the paper. Different techniques may be employed to correctly compute the credit, such as the manual annotation by the authors of the data that are more relevant in their own assessment to the economy of the paper, or computations performed through NLP techniques to infer the importance of a citation.
	\item \emph{Credit produced by self-citations} Data credit, being built on top of traditional citations, inherits some of its problems. Authors, using self-citations, may generate and distribute credit to themselves, making their work appear much more impactful that it really is in reality. Different strategies may be exploited in this scenario, ranging from ignoring completely the credit generated from self-citations to applying a discount factor.
	\item \emph{Generic citations} As we discussed, citations may go to the whole database, or to large views in the database itself. In this case, credit may be assigned indiscriminately to large portions of data, losing the ability to accurately identify parts of the database that have high impact, and highlighting the whole database as being important, without really identifying any interesting part of it. This problem may also have different solutions, such as ignoring queries that are too ``general'' and considering only queries that are discriminative.
	\item \emph{Different types of credit} In the real world, there are different types of research communities interested in different information in a database. Doctors' interests and queries may differ from the interests and queries of ophthalmologists or pharmacists. For this reason, only distributing one generic credit generated from all possible queries may simply highlight data that are important in general, without taking into consideration the specific needs of communities. One possibility is to distinguish the type of credit, e.g., have one credit generated from queries coming from doctors, another type of credit generated from queries submitted by ophthalmologists, etc. In this way, it will be possible to accurately tailor the process of credit distribution around the information need of different categories of users. 
\end{enumerate}}

\rone{\paragraph{Credit Generation vs Credit Distribution} We note that, in our experiments, we always assumed that the credit carried by an output tuple is 1. Thus, each tuple in the output has equal importance. This in general may not be true, since different tuples in the output may have different weight, depending on the context of the citation. For example, data that is fundamental for the results of a paper may have more credit than data being cited as a reference. 
\emph{Credit generation}, i.e. the process by which the credit of the output tuples is decided, is research problem with its own dignity and complexities, and we did not face it in this paper.}

\rone{From the point of view of the model, even when the credit of the output tuples is different than 1, nothing needs to change in the models presented here, since they were defined for a generic value $k$. We note that, if the quantity of credit carried by an output tuple changes, as a consequence the final distribution will change, since certain tuples will be more ``impactful'' (i.e., distribute more credit) than others. With different quantities of credit, therefore, new results, different from the ones obtained in the previous sections, may be found. These results will depend on the nature of the context and the quantity of credit being considered. }

\rone{\paragraph{On the choice of the DS} Depending on the type of task at hand, a different choice may be made for the DS to use. When the user only wants to highlight the tuples being used in the database by a workload, the lineage-based DS is sufficient. When the user wants to know also the relative impact of tuples in the context of the query, the other DSs may be used. This may be true for applications such as data pricing, where we want to give a price to the parts of a database and credit may become a criterion to decide this price. In this context, other forms of provenance may be preferred since they allow to better understand the actual importance of data. 
While the real-world example that we used showed that the four DSs behave the same, this was due to the specific nature of the data and the queries being used. }

\rone{In reality, the why-provenance of a query differs from the lineage of the same query whenever the output tuples can be computed in more than one way by the query, i.e., if there is more than one witness. 
While at the best of our knowledge there isn't any work that explores SQL query logs to validate the presence of this diversity, we still think this to be true in many case.
To support this opinion, the work by \citet{BonifatiMT17} showed that in the context of SPARQL query logs submitted to various databases such as DBpedia and Wikidata, more than $90\%$ of these queries are of type select, and more than $30\%$ perform join operations through the and operator. These queries moreover contain triple patterns with cardinalities that range from 1 to 11 triples, highlighting their big complexity in certain cases. 
These queries, that many times are converted in their SQL versions, are composed by join operations that may result in why-provenances with cardinality bigger than 1. 
Other works, such as \cite{Vogelsgesang2018get}, showed that operations such as Inner joins can be found in at least $4.5\%$ of queries in the considered workload, with a maximum number of times that operator is used in the same query equal to $164$. Outer joins were found in $1\%$ of the queries, and used up to $247$ times in the same query. This is another evidence of the potentiality of the fact the why-provenances may become quite complex. 
}
