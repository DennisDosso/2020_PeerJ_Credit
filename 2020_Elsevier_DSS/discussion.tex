\section{Discussion}
\label{sec:discussion}

\rtwo{In this paper we focused on Credit Distribution, the problem of distributing credit generated by a citation to the parts of the database being used by the query subsumed by that citation.
A different problem is credit generation, the task of generating credit to be then distributed to the tuples. 
Credit generation presents a series of issues shared also by the standard citation practice both traditional and to data. For instance, to define the the quantity of credit to be generated for a given citation is still an open problem. Different types of citations may generate different quantities of credit. Data cited as related to the results or as useful for previous work of a study may generate less credit than other data extensively used to produce the results presented in a paper. The computation of the credit could be done manually (even though we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still far from reaching both for data and traditional citations. For this reason, for the time being, a uniform credit assignment looked more appealing and realistic to us.
\todo[size=\scriptsize]{GMS: I commented out a list of items I did not agree much with. Please take a look and resume what you think is good for you (if any).}}

%% list commented OUT (11 Dec 2021)
\eat{
\begin{enumerate}
	\item \emph{How much credit should be generated?} Different types of citations may generate different quantities of credit. Data cited as related to the results or as useful for previous work of a study may generate less credit than other data extensively used to produce the results presented in a paper. The computation of the credit could be done manually (even though we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still far from reaching both for data and traditional citations. For this reason, for the time being, a uniform credit assignment looked more appealing and realistic to us.\todo[size=\scriptsize]{GMS: commented out the part about NLP; it does not make sense to me. and removed self-citations, that's debatable, not data specific and we do not want to go there.}
	%Different techniques may be employed to compute credit reflecting the impact of the data being cited. The manual annotation by the authors of the data that are more relevant to the economy of the paper is a possibility . Some forms of automatic annotation could be or computations performed through NLP techniques to infer the importance of a citation based on the context of the text where it is cited.
	%\item \emph{Credit produced by self-citations} Data credit, being built on top of traditional citations, inherits some of its problems. Authors, using self-citations, may generate and distribute credit to themselves, making their work appear much more impactful that it actually is. Different strategies may be exploited in this scenario, ranging from ignoring completely the credit generated from self-citations to applying a discount factor to control it.
	\item \emph{Generic citations} As we mentioned, citations may go to the whole database, or to views of the database computed using a big portion of its data. In this case, credit may be assigned indiscriminately to large portions of data, losing the ability to accurately identify parts of the database that have high impact. In this case it is also possible to ignore queries that are too ``general'' and considering only queries that are discriminative enough.\todo[size=\scriptsize, color=green]{this is not about credit generation but distribution. I do not think this is needed (+ I do not know if I agree with this. remove?)}
	\item \emph{Different types of credit} In the real world, there are different types of research communities interested in information in a database. Doctors' interests and queries may differ from the interests and queries of ophthalmologists or pharmacists. For this reason, only distributing one generic credit generated from all possible queries coming from this heterogeneous set of users may simply highlight data that are important in general, without taking into consideration the specific their specific and different needs. One possibility is to keep separated the credit generated by different types of users, e.g., have one type of credit generated from queries coming from doctors, another type of credit generated from queries submitted by ophthalmologists, etc. In this way, it will be possible to accurately tailor the process of credit distribution around the information need of different categories of users. 
\end{enumerate}
}
 
 

\rone{In our experiments, we assumed that the credit carried by an output tuple is one. Thus, each tuple in the output has equal importance. As described above, this assumption may be revised and different credit to different output tuples may be assigned following a given shared algorithm.}

%% again? redundant with above
%This in general may not be true, since different tuples in the output may have different weight, depending on the context of the citation. For example, data that is fundamental for the results of a paper may have more credit than data being cited as a reference. 
%\emph{Credit generation}, i.e. the process by which the credit of the output tuples is decided, is a research problem with its own dignity and complexities, and we did not face it in this paper.}

\rone{Nonetheless, from the distribution models viewpoint no change is required since the DCD is defined for a generic value $k$. Of course, note that if the quantity of credit carried by an output tuple changes, as a consequence the final distribution will change too, since certain tuples will be more ``impactful'' (i.e., distribute more credit) than others.}

\rone{\paragraph{On the choice of the DS.} Depending on the task at hand, one DS may be preferred to another. When we want to highlight the tuples being used in the database by a workload, the lineage-based DS may be sufficient. When we also want to know the relative impact of tuples in the context of the query, the other DSs should be used since they allow us to better understand the importance of data.}

\todo[size=\scriptsize]{GMS: Not superconvinced of the following paragraph. is it good to talk about SPARQL when we say that relational DBs are still widely used? Alternative example with SQL? Or do we just remove it?}\rone{In the real-world based experiment, we showed that the four DSs behave the same, this was due to the specific nature of the data and the queries being used. However, the why-provenance of a query for example differs from the lineage of the same query whenever the output tuples can be computed in more than one way by the query, i.e., if there is more than one witness.
There re several situations where the user-submitted queries present different distribution of credit.
For instance, the work by \citet{BonifatiMT17} showed that in the context of SPARQL query logs submitted to various databases such as DBpedia and Wikidata, more than $90\%$ of these queries are of type select, and of those more than $30\%$ perform join operations through the \texttt{and} operator. These queries contain triple patterns with cardinalities that range from one to eleven triples, thus showing some complexity that can be caught by why- and how-provenance based DSs.} 

\rone{Other works, such as \cite{Vogelsgesang2018get}, showed that operations such as inner joins can be found in at least $4.5\%$ of queries in the considered workload, with a maximum number of times that operator is used in the same query equal to $164$. Outer joins were found in $1\%$ of the queries, and used up to $247$ times in the same query. This is another evidence of the potentiality of the fact the why-provenances may become quite complex. 
}

\rtwo{From a complexity standpoint, all four DS present a similar complexity since we focused on SPJ queries. Although responsibility has been found to be hard to compute in more general  cases, that we did not consider in this work.  Speaking in terms of complexity of implementation, lineage can be thought as the easiest form of provenance, since it only cares about a tuple being used, while the other provenances also need additional information to be taken into consideration.}
