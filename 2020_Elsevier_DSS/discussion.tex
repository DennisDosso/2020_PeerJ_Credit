\section{Discussion}
\label{sec:discussion}

\rtwo{\paragraph{On the problem of Credit Generation} In this paper we focused on Credit Distribution, the problem of distributing credit generated by a citation to the parts of the database being used by the query subsumed by that citation.
A different problem is Credit Generation, the task of generating credit to be then distributed to the tuples. 
Credit Generation presents a series of issues shared also by the standard citation practice both traditional and to data. For instance, to define the  quantity of credit to be generated for a given citation is still an open problem. Different types of citations may generate different quantities of credit. Data cited as related to the results or as useful for previous work of a study may generate less credit than other data extensively used to produce the results presented in a paper. The computation of the credit could be done manually (even though we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still far from reaching both for data and traditional citations. For this reason, for the time being, a uniform credit assignment looked more appealing and realistic to us.
}

\todo[size=\scriptsize]{GMS: I commented out a list of items I did not agree much with. Please take a look and resume what you think is good for you (if any). -- DD: Some of the points were raised because of Reviewer 2. Since we discuss about them in the first paragraph, we can keep the list out of the paper. I added another paragraph to add more meat for reviewer 2, it can be removed too.} 
\rtwo{We also mention the problem of \emph{transitive credit distribution}, i.e., how to transitively propagate credit from one cited unit to another unit that was used to produce the one being cited. Considering transitive credit distribution, it is possible to envision a graph of cited units that propagate credit between them depending on the influence of one work to another that cited it. How to propagate credit is an open and non-trivial problem that needs to consider the importance and impact of a citation in a work, being it a paper or data, and how to eventually discount the quantity of credit when propagated.}



%% list commented OUT (11 Dec 2021)
\eat{
\begin{enumerate}
	\item \emph{How much credit should be generated?} Different types of citations may generate different quantities of credit. Data cited as related to the results or as useful for previous work of a study may generate less credit than other data extensively used to produce the results presented in a paper. The computation of the credit could be done manually (even though we must consider the complexity of the task, human biases and the resources required to carry it out) or automatically, but it must be based on a shared definition of impact which is still far from reaching both for data and traditional citations. For this reason, for the time being, a uniform credit assignment looked more appealing and realistic to us.\todo[size=\scriptsize]{GMS: commented out the part about NLP; it does not make sense to me. and removed self-citations, that's debatable, not data specific and we do not want to go there.}
	%Different techniques may be employed to compute credit reflecting the impact of the data being cited. The manual annotation by the authors of the data that are more relevant to the economy of the paper is a possibility . Some forms of automatic annotation could be or computations performed through NLP techniques to infer the importance of a citation based on the context of the text where it is cited.
	%\item \emph{Credit produced by self-citations} Data credit, being built on top of traditional citations, inherits some of its problems. Authors, using self-citations, may generate and distribute credit to themselves, making their work appear much more impactful that it actually is. Different strategies may be exploited in this scenario, ranging from ignoring completely the credit generated from self-citations to applying a discount factor to control it.
	\item \emph{Generic citations} As we mentioned, citations may go to the whole database, or to views of the database computed using a big portion of its data. In this case, credit may be assigned indiscriminately to large portions of data, losing the ability to accurately identify parts of the database that have high impact. In this case it is also possible to ignore queries that are too ``general'' and considering only queries that are discriminative enough.\todo[size=\scriptsize, color=green]{this is not about credit generation but distribution. I do not think this is needed (+ I do not know if I agree with this. remove?)}
	\item \emph{Different types of credit} In the real world, there are different types of research communities interested in information in a database. Doctors' interests and queries may differ from the interests and queries of ophthalmologists or pharmacists. For this reason, only distributing one generic credit generated from all possible queries coming from this heterogeneous set of users may simply highlight data that are important in general, without taking into consideration the specific their specific and different needs. One possibility is to keep separated the credit generated by different types of users, e.g., have one type of credit generated from queries coming from doctors, another type of credit generated from queries submitted by ophthalmologists, etc. In this way, it will be possible to accurately tailor the process of credit distribution around the information need of different categories of users. 
\end{enumerate}
}

\rone{In our experiments, we assumed that the credit carried by an output tuple is one. Thus, each tuple in the output has equal importance. As described above, this assumption may be revised and different credit to different output tuples may be assigned following a given shared algorithm.}

%% again? redundant with above
%This in general may not be true, since different tuples in the output may have different weight, depending on the context of the citation. For example, data that is fundamental for the results of a paper may have more credit than data being cited as a reference. 
%\emph{Credit generation}, i.e. the process by which the credit of the output tuples is decided, is a research problem with its own dignity and complexities, and we did not face it in this paper.}

\rone{Nonetheless, from the distribution models viewpoint no change is required since the DCD is defined for a generic value $k$. Of course, note that if the quantity of credit carried by an output tuple changes, as a consequence the final distribution will change too, since certain tuples will be more ``impactful'' (i.e., distribute more credit) than others.}



\rone{\paragraph{On the choice of the DS} Depending on the task at hand, one DS may be preferred to another. When we want to highlight the tuples being used in the database by a workload, the lineage-based DS may be sufficient. When we also want to know the relative impact of tuples in the context of the query, the other DSs should be used since they allow us to better understand the importance of data.}

% \todo[size=\scriptsize]{GMS: Not superconvinced of the following paragraph. is it good to talk about SPARQL when we say that relational DBs are still widely used? Alternative example with SQL? Or do we just remove it?}
\rone{In the real-world based experiment, we showed that the four DSs behave the same, this was due to the specific nature of the data and the queries being used. However, the why-provenance of a query for example differs from the lineage of the same query whenever the output tuples can be computed in more than one way by the query, i.e., if there is more than one witness. This is usually true when the join and projection operators are used in the query.
% There are several situations where the user-submitted queries present different distribution of credit.
% For instance, the work by \citet{BonifatiMT17} showed that in the context of SPARQL query logs submitted to various databases such as DBpedia and Wikidata, more than $90\%$ of these queries are of type select, and of those more than $30\%$ perform join operations through the \texttt{and} operator. These queries contain triple patterns with cardinalities that range from one to eleven triples, thus showing some complexity that can be caught by why- and how-provenance based DSs.
} 

\rone{Works such as \cite{Vogelsgesang2018get} study the characteristics of query workloads and the complexity of their queries and give us an idea of what type of queries may be found in the real world, and how their provenances may change. In particular, \cite{Vogelsgesang2018get} showed that operations such as inner joins can be found in at least $4.5\%$ of queries in the considered workload, with a maximum number of times that operator is used in the same query equal to $164$. Outer joins were found in $1\%$ of the queries, and used up to $247$ times in the same query. }
\rone{\cite{Remil2021makes} showed that in the query workload of a company 520 queries out of 140K presented the join operator, while 3470 presented projections. }
\rone{\cite{Jain2016sqlshare} shows instead that 11\% of the queries in their considered workflow used outer join. Moreover, 2.5\% of the considered views access other datasets, and 10\% of the queries logged in the system access datasets that the query author does not own. It also showed that many queries are short in their considered workload in terms of ASCII characters being used (circa 20\% are under 100 characters), on the other hand the longest query range up to 11375 characters. The simple length is not necessarily equivalent to complexity, thus the authors also showed that, while many of the considered queries have less than 4 distinct operators, a percentage around 30 and 60\% of queries, depending on the workload, present a number of distinct operators between 4 and 8. Finally, the considered queries also showed a higher entropy, i.e., they were particularly different among them.}

\rone{
These works provide us evidence of the fact that, potentially, why- and how-provenances may become quite complex in certain cases and provide a distribution of credit different from the one obtained with lineage. 
}

\rtwo{From a complexity standpoint, all four DS present a similar complexity since we focused on SPJ queries. Although responsibility has been found to be hard to compute in more general  cases, that we did not consider in this work.  Speaking in terms of complexity of implementation, lineage can be thought as the easiest form of provenance, since it only cares about a tuple being used, while the other provenances also need additional information to be taken into consideration.}
