\section{Conclusions}
\label{section:conclusions}

This paper expanded on our previous work on data credit and data credit distribution by defining two new distribution strategies, based on the why- and how-provenance. 
The first distribution is based on the concept of witness, and it can give more credit to tuples that appear in more than one witness. 
In other words, tuples that are more important to the query and are used in different ways by a query are also rewarded more by the distribution.
The second distribution, based on how-provenance, considers the frequency in which a tuple or a combination of tuples is used in the query through the provenance polynomial information. In this sense, it is even more sensitive than the first one.

To show the differences between the three DS (also considering the one based on lineage, defined in our previous work), we performed different experiments on GtoPdb, a curated scientific relational database. 
In the first set of experiments, we used SPJ queries extracted by data citations present in papers published in the British Journal of Pharmacology. 
Employing these queries, we were able to distribute the credit to the tuples in different tables of the database, highlighting the tuples used more than others. 
We showed that with these queries, the three strategies produce the same distribution. With the specific type of queries that do not present self-joins, the formulas at the base of the strategies have the same output. In this particular case, the tuples are used in the same way by the queries; thus, the DSs do not register any particular difference in the tuples' role.

In the second and third sets of experiments, we synthetically produced more complex queries, i.e., nested queries whose provenance polynomials presents coefficients and exponents bigger than $1$.
In this way, we showed that, even though all three DS can highlight all the tuples used by the queries in the database, the three have different behaviors. 
While the DS based on lineage rewards all the tuples used by a query in equal measure, the strategy based on why-provenance tends to reward the tuples more critical to the query. 
In particular, why-provenance can consider the different ways in which one tuple is used in a query.  
How-provenance is even more sensitive to the tuples' role: it can also consider the frequency by which a tuple or a set of tuples is used in the case of more complex queries. Depending on the goal of a user, one provenance may be preferred to another. 

In the fourth set of experiments, we showed how, compared with traditional citations, the credit distributed with the three strategies works as a new tool highlighting different aspects of an author's role in the research context identified by queries. Authors with a limited number of citations can still have a high quantity of credit due to the importance of the data to which they contributed to the queries. 

In future work, we plan to explore the different potential applications of credit on relational databases.
One example is the so-called \emph{data pricing}. Data pricing consists of giving a price to a query submitted by a user who wants to buy the produced information. Currently, a commonly used strategy to face data pricing is based on query rewriting. A database stores a set of views correlated with their price. When a new query arrives, the system tries to rewrite it using the stored views and obtain a query price. This process is computationally expensive.
We plan to distribute credit through carefully planned and representative queries and use it as information to define a new, faster, and potentially more flexible pricing function.

Another application is \emph{data reduction}~\cite{milo2019getting}, concerned with reducing the vast mole of data that is produced in the evolving world of research and information technology. Data reduction deals with different aspects of dealing with huge amounts of data, such as finding reduced and relevant data streams from the multiple gigabytes of data produced by big data systems every second or dealing with the curse of dimensionality which requires unbounded computational resources to uncover actionable knowledge patters~\citep{ur2016big}.

Data credit can also help to find ``hotspots'' and ``coldspots''. A hotspot is data in a database (a tuple or a single attribute, for example) that presents a high quantity of credit and is therefore valuable for the set of queries that distributed that credit. 
On the other hand, a coldspot is data that present low quantities of credit and can be considered useless or less relevant and can therefore be removed or moved in another cheaper and less efficient memory location. 
