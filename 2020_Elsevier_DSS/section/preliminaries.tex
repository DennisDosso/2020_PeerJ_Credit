\section{Data Provenances}
\label{section:preliminaries}
In this section, we present the three types of provenance used in this paper:  lineage, why-provenance, and how-provenance. 
\rtwo{We also discuss of Causality and Responsibility that, even though are not forms of data provenance \emph{per se}, they are still used as basis to define a DS}. 

\subsection{Lineage}
Lineage was first introduced by \citet{lineageCui}. Given a database instance $I$ and query $Q$, lineage associates with each tuple $o \in Q(I)$ the set of tuples in the input
%That is, the lineage of a tuple is the set of tuples 
that contributed to its ``production''~\citep{CheneyProvSurvey}.
As an example, consider the following SQL query \texttt{Q1}, applied to the database described in Table \ref{table:running_example}, that asks for the names of families curated by researchers based in the United Kingdom (UK):

\vspace{2mm}
{\footnotesize
\begin{adjustwidth}{25pt}{0pt}
\begin{verbatim}
		Q1: SELECT DISTINCT f.name
		FROM family AS f JOIN contributor2family AS c2f 
		ON f.id = c2f.family_id
		JOIN contributor AS c ON c2f.contributor_id = c.id
		WHERE c.country = 'UK'
\end{verbatim}	
\end{adjustwidth}
}
\vspace{2mm}

\begin{table}[hbt]
\centering
  \begin{tabular}{|l||c|}
  \hline
    id & name\\
    \hline
    $o_1$ &  Dopamine Receptors\\
    $o_2$ & YANK Family\\
    \hline
  \end{tabular}
  \begin{tabular}{c}
  	lineage   \\
  	$\{f_1, c2f_1, c_1, c2f_2, c_2\}$ \\
  	$\{ f_4, c2f_4, c_1\}$ \\
  \end{tabular}
    \caption{Result of an SQL query applied to the database instance in Table \ref{table:running_example}, which asks for the names of families curated by a researcher based in the UK. Attribute \texttt{id} is not part of the output and was added to succinctly identify each tuple as provenance token. Each tuple is also annotated with its lineage.}
  \label{table:result}
\end{table}

Table \ref{table:result} shows the query result set, which consists of two tuples. We add an extra  attribute \texttt{id} so that we can easily refer to each result tuple.  
The lineage for tuple $o_1$ is the set $\{f_1, c2f_1, c_1, c2f_2, c_2\}$, since the tuple $f_1$ was joined with $c2f_1$ and then with $c_1$, and was also joined with $c2f_2$ and $c_2$. No other tuple is used in the database to produce $o_1$.
For tuple $o_2$ the lineage is $\{ f_4, c2f_4, c_1\}$.
Lineage is defined for each tuple of the output, and can differ between tuples.

\subsection{Why-Provenance}
Why-Provenance was first defined in terms of a deterministic semistructured data model and query language \citep{WhyProvBuneman}. 
While why-provenance can be defined in many ways, we refer to \citep{CheneyProvSurvey}, where it is expressed in terms of the relational model using the relational algebra.

In particular, while lineage aims to find all and only the tuples in the input relevant to the production of an output tuple, why-provenance aims to find sub-instances of the input that ``witness'' a part of the output. 
Given a tuple $t$ in the query's output, a \emph{witness} is any sub-instance of the database that produces $t$.
In particular, the whole database and the lineage of $t$ are both witnesses of $t$.
% \scream{the next sentence was unclear, I modified but you should check.}
Since the definition of witness allows for the presence of ``irrelevant'' tuples, the set of all witnesses is finite (since the database instance $I$ is finite), but it is potentially exponentially large~\citep{CheneyProvSurvey}.

\citet{WhyProvBuneman} defined the why-provenance of an output tuple $t$ in the result $Q(I)$ as a special \emph{subset} of the set of witnesses called the \emph{witness basis}.
The witnesses of the basis depend on $ Q $; thus, each basis's size is bounded by the size of $ Q $. The witnesses of the basis exclude tuples that are irrelevant to $t$ being produced by $Q$, and thus the basis tends to be very small compared to the set of all possible witnesses~\citep{CheneyProvSurvey}.
The witnesses are also {\em minimal}, in the sense that if one tuple is removed from one of these witnesses, it cannot produce the output. % This is not true for the lineage. For example, it is sufficient to consider the lineage of $o_1$ in the example above, where the tuples $c2f_2$ and $c_2$ may be eliminated without affecting the output. 


%FORMAL DEFINITION
%\begin{definition}{Witness~\citep{CheneyProvSurvey}}\\
%\label{def:witness}
%	Let $I$ be a database instance, $Q$ a query over $I$, and $t$ a tuple in $Q(I)$. An instance $I' \subseteq I$ is a \emph{witness} for $t$ with respect to $Q$ if $t \in Q(I')$.
%\end{definition}
%In other words, a witness is a set of tuples in the input that guarantees the presence of $t$ in the output. Any sub-instance of the database that produces $t$ is a witness. In particular, the whole database and the lineage of $t$ are both witnesses of $t$. We can define the set of all the witnesses as $Wit(Q, I, t) = \{ J \subseteq I | t \in Q(J) \}$.
%This set is finite (if $I$ is also finite), but it is potentially exponentially large due to the possibility for witnesses to contain ``irrelevant'' tuples. 
%Recalling that $TupleLoc$ is the set of all the tuple locations, we say that the witness basis belongs to $\mathcal{P}(\mathcal{P}(TupleLoc))$, i.e. it is a set of sets of tuples. We note that if $TupleLoc$ is finite, then also $\mathcal{P}(\mathcal{P}(TupleLoc))$ is finite.

%The formal definition of why-provenance in the context of relational databases is as follows:
%
%\begin{definition}{Why-provenance~\citep{CheneyProvSurvey}}\\
%	Let $Q$ be an $SPJRU$ query. Let $I$ be a database instance, and $t$ be a tuple in $Q(I)$. Then, the \emph{why-provenance} (\emph{witness basis}) of $t$ according to $Q$ and $I$, denoted as $Why(Q, I, t)$, is a subset of $\mathcal{P}(\mathcal{P}(TupleLoc))$ defined as follows:
%	\[
%\begin{array}{rl}
%      Why(\{t\}, I, \{u\}) = & \begin{cases}
%		\{ \emptyset \}, & \mbox{if } t = u\\
%		\emptyset, & \mbox{otherwise.}\\
%	\end{cases}\\
%	Why(R, I, t) = & \begin{cases}
%		\{\{(R, t)\}\}, & \mbox{if } t \in R(I),\\
%		\emptyset, & \mbox{otherwise.}\\
%	\end{cases}\\
%	Why(\sigma_{\theta}(Q), I, t) = & \begin{cases}
%		Why(Q, I, t), & \mbox{if } \theta(t),\\
%		\emptyset, & \mbox{otherwise.}
%	\end{cases}\\
%	Why(\pi_U(Q), I, t) = & \bigcup \left \{Why(Q, I, u) | u \in Q(I), t = u[U] \right \} \\
%	Why(\rho_{A \mapsto B}(Q), I, t) = & Why(Q, I, t[B \mapsto A])\\
%	Why(Q_1 \Join Q_2, I, t) = & Why(Q, I, t[U_1]) \Cup Why(Q_2, I, t[U_2]) \\
%	Why(Q_1 \cup Q_2, I, t) = & Why(Q_1, I, t) \cup Why(Q_2, I, t)\\
%\end{array}
%\]
%Where the symbol $\Cup$ takes all the pairwise unions of two collections, working in a similar way to the strict union defined above for lineage. That is: $S \Cup \bot = \bot \Cup S = \bot$, and $S \Cup T = \{s \cup t | s \in S, t \in T\}$ otherwise.
% \end{definition}
% 
% As can be inferred from this definition, the witnesses of the witness basis depend on the syntax of $Q$, thus the size of each witness basis is bounded by the size of $Q$. In particular, the witnesses of the witness basis exclude tuples that are irrelevant to $t$ being produced by $Q$. Thus, the basis tends to be very small when compared to the set of all possible witnesses~\citep{CheneyProvSurvey}.
 

\begin{table}[hbt]
\centering
  \begin{tabular}{|l|c|}
  \hline
    id & name\\
    \hline
    $o_1$ &  Dopamine Receptors\\
    $o_2$ & YANK Family\\
    \hline
  \end{tabular}
  \begin{tabular}{c}
  	why-provenance   \\
  	$\{\{f_1, c2f_1, c_1\}, \{f_1, c2f_2, c_2\}\}$ \\
  	$\{\{ f_4, c2f_4, c_1\}\}$ \\
  \end{tabular}
    \caption{Result of a SQL query applied on the database of Table \ref{table:running_example} with the why-provenance of the corresponding results.}
  \label{table:result_why_prov}
\end{table}
 
In a sense, each witness in the witness basis captures one possible way in which the query can generate the output. 
To better understand this, consider the example in Table \ref{table:result_why_prov}, where each tuple in the result of query \texttt{Q1} is annotated with its why-provenance. 

The why-provenance of output tuple $o_2$ has only one witness, which coincides with its lineage. This happens because there is only one way this output tuple can be produced, i.e., for tuple $f_4$ to be joined with $c2f_4$ and $c_1$.
On the other hand, $o_1$ has a witness basis with of two witnesses, since there are two possible ways in which the query can generate $o_1$. 
One possibility is that $f_1$ is joined with $c2f_1$ and $c_1$ (the first witness), and the second possibility is that $f_1$ is joined with $c2f_2$ and $c_2$ (the second witness). This means that to generate $o_1$, it is sufficient that only one of the two witnesses is present in the input database. 

\subsection{How-Provenance}
\label{section:how_provenance_tuples}

While why-provenance describes the source tuples that witness an output tuple in the result of the query, it leaves out  information about how the source tuples are used.
How-provenance was therefore defined in \citep{howProvenanceGreen} to capture this information using a \emph{semiring} algebraic structure, and is a form of provenance that takes the form of a \emph{polynomial}.
% SOME FORMALISM
%A semiring $K$ is a \emph{set} equipped with two operations, typically denoted with the symbols $+$ and $\cdot$, satisfying the following axioms ~\cite[pg. 26]{berstel1985theory}:
%\begin{enumerate}
%	\item The set $K$ is a \emph{commutative monoid} for the operator $+$ with a neutral element $0$. Therefore, it has these properties:
%		\begin{enumerate}
%			\item $(a + b) + c = a + (b + c)$ (associative property)
%			\item $0 + a = a + 0 = a$ ($0$ is the neutral element) 
%			\item $a + b = b + a$ (commutative property)
%		\end{enumerate}
%	\item The set $K$ is a \emph{monoid} with identity element $1$. Therefore, it has these properties:
%		\begin{enumerate}
%			\item $(a \cdot b) \cdot c = a \cdot (b \cdot c)$ (associative property)
%			\item $1 \cdot a = a \cdot 1 = a$ ($1$ is the neutral element)
%		\end{enumerate}
%	\item Multiplication is distributive on addition, i.e.:
%		\begin{enumerate}
%			\item $a \cdot (b + c) = (a \cdot b) + (a \cdot c)$
%			\item $(a + b) \cdot c = (a \cdot c) + (b \cdot c)$
%		\end{enumerate}
%	\item Multiplication by $0$ annihilates $K$, i.e. $\forall x \in K, 0 \cdot x = x \cdot 0 = 0$
%\end{enumerate}

The key idea in \citet{howProvenanceGreen} is to use the two operators $+$ and $\cdot$ to represent two basic transformations that source tuples undergo as a result of applying a relational query to a database~\citep{CheneyProvSurvey}. 
Two tuples may either be joined together, as an effect of a join (represented with the $\cdot$ operator) or merged via union or projection (represented with the $+$ operator).


\begin{table}[]
\centering
  \begin{tabular}{|l|c|}
  \hline
    id & name\\
    \hline
    $o_1$ &  Dopamine Receptors\\
    $o_2$ & YANK Family\\
    \hline
  \end{tabular}
  \begin{tabular}{c}
  	how-provenance   \\
  	$f_1 \cdot c2f_1 \cdot c_1 + f_1 \cdot c2f_2 \cdot c_2$ \\
  	$f_4 \cdot c2f_4 \cdot c_1$ \\
  \end{tabular}
    \caption{Result of the example SQL query \texttt{Q1} with the corresponding how-provenances of the output tuples annotated.}
  \label{table:result_how_prov}
\end{table} 

Table \ref{table:result_how_prov} shows a simple example in which the two output tuples of our running example are annotated with their respective how-provenances. 
Tuple $o_2$ was produced through the join among the input tuples $f_4, c2f_4$, and $c_1$. The three provenance tokens are, therefore  ``multiplied'' together. 
The case of $o_1$ is slightly more complex. This tuple, as already discussed, can be obtained through two different joins. The two monomials composing the polynomial represent these two alternatives. They correspond, in a way, to the witnesses of the why-provenance of $o_1$.
The $+$ operator represents the fact that the two monomials describe alternative derivations. The output tuple is the result of a merge of two distinct tuples after the projection on the attribute \texttt{name}. This merge is due to the fact that the result of a relational algebra expression is always a {\em set} of tuples, which corresponds to the presence of the \texttt{DISTINCT} operator in an SQL query. 
This simple example gives the basic idea behind how-provenance and how it allows us to track the operations that produced an output tuple. 

% talking a little bit about coefficients and exponents
Provenance polynomials may also have monomials whose exponents and/or coefficients are greater than one, for example, $3f_1 \cdot c2f_1 \cdot c_1 + f_1 \cdot c2f_2^3 \cdot c_2^3$. This is a polynomial of a tuple produced by a query where the result of the join between the tuples $f_1$, $c2f_1$, and $c_1$ is produced three times and then merged (e.g. as the result of a union), and the tuples $c2f_2$ and $c_2$ are used three times in the operation described by the second monomial (e.g., with nested queries). 
% \scream{Why would the join tuple be produced 3 times?  Perhaps as a result of a union? Projection doesn't make sense}

\rtwo{\subsection{Causality and Responsibility}}
\label{sec:responsibility}

A formal study of causality was initiated in \cite{Halpern2013Causality,ChocklerH04} and later expanded by \citet{MeliouGMS11} to define the causes of answers and non-answers to queries. Causality is, more precisely, related to the provenance of a query result such as why-provenance. Causality adds information to the one already provided by the provenance.

In the following we define causality and responsibility as done in \cite{MeliouGMS11}. Differently from \cite{MeliouGMS11}, we only focus on answers of a query, and not non answers, since they are not relevant in the context of this paper.
Let $R_1, \dots, R_k$ be the relation names of a standard relational schema, $D$ be a database instance and $q$ a conjunctive query. We also call $D^n \subseteq D$ the set of \emph{endogenous tuples}, i.e. the tuples being actually considered to be possible causes of a query output; while $D^x = D - D^n$ is the set of \emph{exogenous tuples}, the tuples being considered external, unconcerned factors, thus deemed not to be possible causes. 
This distinction between endogenous and exogenous tuple is application dependent, and it can be done by the user at query time. 
One example is with probabilistic databases with uncertain tuples, where erroneous data may be contained. By considering these uncertain tuples as part of the exogenous tuples dataset, we are factoring them out of the computation of causality. 

Then, given a tuple $\bar{a}$ with the same arity as the query's answer, we write $D \vDash q(\bar{a})$ when $\bar{a}$ is an answer to $q$ on $D$, and write $D \nvDash q(\bar{a})$ when $\bar{a}$ is a non-answer to $q$ on $D$.
Causality is defined as follows:

\begin{definition}{Causality \cite{MeliouGMS11} }\\
	Let $t \in D^n$ be an endogenous tuple, and $\bar{a}$ a possible answer for $q$. Then:
	\begin{enumerate}
		\item $t$ is called a \emph{counterfactual cause} for $\bar{a}$ in $D$ if $D \vDash q(\bar{a})$ and $D - \{t\} \nvDash q(\bar{a})$
		\item $t \in D$ is called an \emph{actual cause} for $\bar{a}$ if there exists a set $\Gamma \subseteq D^n$, called \emph{contingency} for $t$, such that $t$ is a counterfactual cause for $\bar{a}$ in $D - \Gamma$.
	\end{enumerate}
\end{definition}

$t$ is a \emph{counterfactual cause} if, by removing it from the database, we remove $\bar{a}$ from the answer. Therefore, it can be fought as a tuple of the lineage which is fundamental for the presence of $\bar{a}$ in the answer.
Vice-versa, $t$ is an actual cause if it is possible to find a contingency set of tuples such that, if that set is removed, only then $t$ becomes fundamental. In other words, when $t$ is an actual cause, even if it was removed from the database, $\bar{a}$ would still be present in the result set thanks to the contingency set. 
Checking the causality degree of tuples is NP-complete in general~\cite{EiterL02}, but \citet{MeliouGMS11} proved that the causality of conjunctive queries may be determined in PTIME.


The notion of \emph{responsibility} was first defined in \cite{ChocklerH04}, and it measure the degree of causality as a function of the size of the smallest contingency set. It allows to rank the tuples in a lineage based on their degree of causality in generating the output. 

\begin{definition}{Responsibility \cite{MeliouGMS11}}
	Let $\bar{a}$ be an answer to a query $q$, and let $t$ be a cause. The \emph{responsibility} of $t$ for the answer $\bar{a}$ is:
	\[
		\rho_t = \frac{1}{1 + min_\Gamma|\Gamma|}
	\]
	where $\Gamma$ ranges over all contingency sets for $t$.
\end{definition}

As can be seen, a counterfactual cause will have the maximum responsibility of $1$, while the bigger the minimum contingency of an actual cause, the smaller its responsibility since more tuples can still guarantee the presence of the answer $\bar{a}$.

While in general computing the responsibility is hard~\cite{ChocklerH04}, \citet{MeliouGMS11} showed that for each query without self-joins the responsibility is either computed in PTIME in the size of the database or checking if it has a responsibility below a given value is NP-hard. 

\begin{table}[]
\centering
  \begin{tabular}{|l|c|}
  \hline
    id & name\\
    \hline
    $o_1$ &  Dopamine Receptors\\
    $o_2$ & YANK Family\\
    \hline
  \end{tabular}
  \begin{tabular}{c}
  	responsibility   \\
  	$f_1: 1, c2f_1: 0.5, c2f_2: 0.5, c_1: 0.5, c_2: 0.5$ \\
  	$f_4: 1, c2f_4: 1, c_1: 1$ \\
  \end{tabular}
    \caption{Result of the example SQL query \texttt{Q1} with the corresponding responsibilities of the lineage tuples.}
  \label{table:result_responsibility}
\end{table} 

As an example, consider Table \ref{table:result_how_prov}, where we reported the tuples result of query \texttt{Q1} together with the tuples of their lineage accompanied with their responsibility values. 
With output tuple $o_1$, the tuple $f_1$ of the lineage is a counterfactual cause, since its contingency set is empty (when removed from the database, $o_1$ disappears from the result set). Consequently, its responsibility is 1. On the other hand, the other tuples of the lineage are all actual causes. $c_1$, for example, has as minimal contingency set $\{c2f_2\}$, and thus its responsibility is $0.5$. 
For the output tuple $o_2$, all the tuples of the lineage are counterfactual causes, and thus they all have responsibility 1.





%MORE FORMALISM
%Now we formally introduce the mathematical framework behind how-provenance~\citep{howProvenanceGreen}.
%Let $K$ be a set containing an element $0$. 
%A $K$-$relation$ is a function $R: U$-$Tuples \mapsto K$ which maps every $U$-tuple in an element in $K$ such that its support, defined as $supp(R) = \{t | R(t) \neq 0\}$, is finite. 
%We remember that a $U$-tuple is a tuple with attributes in the set $U$. The $K$-relation is a finite function which models a relation $R$, tagging each tuple in $R$ with an element of $K$ and each tuple that is not in $R$ with $0$.

%\begin{definition}{Operations on the algebraic structure $(K, 0, 1, +, \cdot)$\citep{howProvenanceGreen}}\\
%\label{definition:how_original}
%	Let $(K, 0, 1, +, \cdot)$ be an algebraic structure with two binary operations $+$ and $\cdot$ and two distinguished elements $0$ and $1$. The operations of the positive $K$-relational algebra are defined as follows:
%	\begin{enumerate}
%		\item \textsf{Empty relation}. For any set of attributes $U$, $\exists \emptyset: U-Tuples \mapsto K | \emptyset(t) = 0$.
%		\item \textsf{Selection} Let $R: U$-Tuples $\mapsto K$ and $\sigma$ be a selection predicate that maps each $U$-Tuple to either 0 or 1. Then $\sigma_\theta(R): U$-Tuples $\mapsto K$ is defined by $(\sigma_\theta(R))(t) = R(t) \cdot \sigma(t)$. 
%		\item \textsf{Projection} Let $R: U$-Tuples $\mapsto K$ and $V \subseteq U$. Then $\pi_V(R): V$-Tuples $\mapsto K$ is defined by $(\pi_V(R))(t) = \sum_{t = t'[V] \vee R(t') \neq 0 }R(t')$.
%		\item \textsf{Union} Let $R_1, R_2: U$-Tuples $\mapsto K$. Then $R_1 \cup R_2: U$-Tuples $\mapsto K$ is defined by $(R_1 \cup R_2)(t) = R_1(t) + R_2(t)$.
%		\item \textsf{Natural join} Let $R_1: U_1$-Tuples $\mapsto K$ and $R_2: U_2$-Tuples $\mapsto K$. Then $R_1 \Join R_2: U_1 \cup U_2$-Tuples $\mapsto K$ is defined by $(R_1 \Join R_2)(t) = R_1(t_1) \cdot R_2(t_2)$, where $t_1 = t[U_1]$ and $t_2 = t[U_2]$.
%	\end{enumerate}
%\end{definition}

%It is observed in \citep{howProvenanceGreen, CheneyProvSurvey} that if the $K$-relational semantics satisfies the same equivalence laws as positive relational algebra operators over bags, i.e. union (+) is associative, commutative and has identity $\emptyset$ and join ($\cdot$) is associative, commutative and distributive over union, and projection and selection commute with each other, as well as with union and join, then $(K, 0, 1, +, \cdot)$ must be a commutative semiring. 
% 
%The semiring operations document \emph{how} each output tuple is produced from source tuples. If each source tuple in a database $D$ is tagged with a distinct id, the semiring gives the how-provenance for each output tuple in the form of a polynomial with coefficient from the set $\mathbb{N}$ of natural numbers and variables from the set of source tuples id. 
%
%For clarity, taking inspiration from the original definition \ref{definition:how_original}, we re-define this definition in a compositional manner, as done with lineage and why-provenance. For this, let us consider the algebraic structure $(\mathbb{N}(TupleLoc), 0, 1, +, \cdot)$, where $\mathbb{N}(TupleLoc)$ is the set of polynomials whose coefficients are the natural numbers and the variable are from the set $TupleLoc$. 
%The how-provenance of an output tuple is a function $\mathcal{H} = How(Q, I, o)$ that returns a polynomial in $\mathbb{N}(TupleLoc)$ called \emph{provenance polynomial}. 
%
%
%\begin{definition}{How-Provenance}\\
%\label{definition:how_provenance}
%		Let $Q$ be a (complex) SPJRU query. Let $I$ be a database instance, and $t$ be a tuple in $Q(I)$. Then, the \emph{how-provenance} of ~$t$ according to $Q$ and $I$, denoted as $How(Q, I, t)$, is an element of the set $\mathbb{N}(TupleLoc)$ defined as follows:
%\[
%	\begin{array}{rl}
%		How(\{u\}, I, t) = & \begin{cases}
%			1, & \mbox{if } t = u,\\
%			0 & \mbox{otherwise}.
%		\end{cases}\\
%		How(R, I, t) = & \begin{cases}
%			(R, t), & \mbox{if } t \in R,\\
%			0 & \mbox{otherwise}.
%		\end{cases}\\
%		How(\sigma_\theta(Q), I, t) = & \theta(t) \cdot How(Q, I, t) \\
%		How(\rho_{A \mapsto B}(Q), I, t) = & How(Q, I, t[B \mapsto A]) \\
%		How(\pi_V(Q), I, t) = & \sum_{u \in supp(Q), u[V] = t} How(Q, I, t) \\
%		How(Q_1 \Join Q_2, I, t) = & How(Q_1, I, t[U_1]) \cdot How(Q_2, I, t[U_2]) \\
%		How(Q_1 \cup Q_2, I, t) = & How(Q_1, I, t) + How(Q_2, I, t)\\
%	\end{array}
%\]
%\end{definition}
%
%We remember that $\{u\}$ is a query expression describing a constant, singleton relation, not a relation value per se. These constants correspond to $K$-relations that assign $1$ to $u$ and $0$ to all other tuples.
%The summation in the projection case is finite since the support of a $K$-relation is assumed to be finite. 
%In the selection rule, $\theta$ is seen as a function $\theta: U$-Tuples $\mapsto \{0, 1\}$.